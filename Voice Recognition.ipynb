{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOr2e1jhgf3BcGSpfycERPG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codewithroger/TTL-Project-Voice-Recognition-/blob/main/Voice%20Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6aho1o-OhHoG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "from tensorflow.keras.models import load_model\n",
        "import joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('/content/Voice_recognintion.h5')\n",
        "\n",
        "# Load the saved LabelEncoder\n",
        "le = joblib.load('/content/Voice_recognintion.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D51zs6V4iIsn",
        "outputId": "c1bba50f-8c0e-4544-e467-0796bbb425d8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(file_name):\n",
        "    try:\n",
        "        audio, sample_rate = librosa.load(file_name, sr=44100)\n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40, fmax=8000)\n",
        "        chroma = librosa.feature.chroma_stft(y=audio, sr=sample_rate)\n",
        "        mel = librosa.feature.melspectrogram(y=audio, sr=sample_rate)\n",
        "        contrast = librosa.feature.spectral_contrast(y=audio, sr=sample_rate)\n",
        "        tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(audio), sr=sample_rate)\n",
        "\n",
        "        # Combine extracted features into a single array\n",
        "        features = np.hstack((\n",
        "            np.mean(mfccs.T, axis=0),\n",
        "            np.mean(chroma.T, axis=0),\n",
        "            np.mean(mel.T, axis=0),\n",
        "            np.mean(contrast.T, axis=0),\n",
        "            np.mean(tonnetz.T, axis=0)\n",
        "        ))\n",
        "\n",
        "        return features\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_name}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "fRRtwdsKiWSv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sound_label(file_name):\n",
        "    feature = extract_features(file_name)\n",
        "    if feature is None:\n",
        "        print(f\"Unable to extract features from {file_name}\")\n",
        "        return None\n",
        "\n",
        "    feature = feature.reshape(1, -1)\n",
        "    predicted_vector = model.predict(feature)\n",
        "    predicted_label = le.inverse_transform(np.argmax(predicted_vector, axis=1))\n",
        "    return predicted_label[0]"
      ],
      "metadata": {
        "id": "RVs7eJPciZSi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_file_name = '/content/Voice_frame_4.wav'\n",
        "predicted_label = predict_sound_label(random_file_name)\n",
        "print(f\"The predicted label for the sound is: {predicted_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhrKVDvFicoN",
        "outputId": "19c87f4a-1f34-4a0f-9b83-cb459b995b14"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533ms/step\n",
            "The predicted label for the sound is: Yogesh\n"
          ]
        }
      ]
    }
  ]
}